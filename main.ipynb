{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea3f071-036e-472b-a6dc-67900e305961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"/kaggle/input/rsna-breast-cancer-detection/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb3bc69-fee4-425c-b03c-e83fcef05a63",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db58f8-f6f4-46a7-968c-ff2fb1962550",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"age\"] = train_df[\"age\"].fillna(train_df[\"age\"].median())\n",
    "#train_df[\"BIRADS\"] = train_df[\"BIRADS\"].fillna(train_df[\"BIRADS\"].median())\n",
    "#train_df = train_df.drop(columns=[\"BIRADS\"])\n",
    "#train_df = train_df.drop(columns=[\"density\"])\n",
    "train_df = train_df.drop(columns=[\"machine_id\"])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b64fbe-00db-40dc-b6d9-386b697895b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the base directory where images are stored\n",
    "BASE_DIR = \"/kaggle/input/rsna-breast-cancer-detection/train_images\"\n",
    "\n",
    "# Function to construct full image path\n",
    "def get_image_path(row):\n",
    "    return os.path.join(BASE_DIR, str(row[\"patient_id\"]), f\"{row['image_id']}.dcm\")\n",
    "\n",
    "# Apply the function to each row\n",
    "train_df[\"image_path\"] = train_df.apply(get_image_path, axis=1)\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e800ad-df9d-44b1-9dc2-270bcfcd1e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base_path = \"/kaggle/input/rsna-breast-cancer-detection/train_images\"\n",
    "\n",
    "train_df['image_path'] = train_df.apply(\n",
    "    lambda row: f\"{image_base_path}/{row['patient_id']}/{row['image_id']}.dcm\", \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de3493-e7fa-495f-88c6-da1dcbc9c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.get_dummies(train_df, columns=['laterality', 'view'], drop_first=False)\n",
    "\n",
    "# Normalize numerical features\n",
    "numerical_cols = ['age']  # add more if needed\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "tabular_data = df.drop(columns=['site_id','invasive', 'biopsy', 'image_id','difficult_negative_case', 'patient_id', 'image_path', 'cancer', 'BIRADS', 'density'])\n",
    "tabular_data = tabular_data.astype(np.float32).values  # ðŸ‘ˆ this is key!\n",
    "labels = df['cancer'].values\n",
    "labels = labels.astype(np.float32)  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56631e-eb99-4000-ad42-a920b85b3f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.get_dummies(train_df, columns=['laterality', 'view'], drop_first=False)\n",
    "\n",
    "# Normalize numerical features\n",
    "numerical_cols = ['age']  # add more if needed\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Include all positive samples\n",
    "positive_df = df[df['cancer'] == 1]\n",
    "\n",
    "# Sample equal or smaller number of negative examples (or a 1:3 ratio)\n",
    "negative_df = df[df['cancer'] == 0].sample(n=len(positive_df) * 1, random_state=42)\n",
    "\n",
    "# Combine and shuffle\n",
    "df_balanced = pd.concat([positive_df, negative_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "tabular_data = df_balanced.drop(columns=['site_id','invasive', 'biopsy', 'image_id','difficult_negative_case', 'patient_id', 'image_path', 'cancer', 'BIRADS', 'density'])\n",
    "tabular_data = tabular_data.astype(np.float32).values  # ðŸ‘ˆ this is key!\n",
    "labels = df_balanced['cancer'].astype(np.float32).values\n",
    "image_paths = df_balanced['image_path'].values.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a43a2a-45e6-4a09-8f40-5bf01564539f",
   "metadata": {},
   "source": [
    "# Model with transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46342233-0d64-47e0-9dd7-cf1cb7b40749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications, Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Function to build the multimodal model\n",
    "def create_multimodal_model(image_shape=(224, 224, 1), tabular_input_dim=4):\n",
    "    # IMAGE INPUT BRANCH\n",
    "    image_input = layers.Input(shape=image_shape, name=\"image_input\")\n",
    "\n",
    "    # Convert grayscale image to RGB by using a Conv2D layer with 3 filters\n",
    "    x = layers.Conv2D(3, (1, 1), padding=\"same\")(image_input)  # Convert grayscale (1 channel) to 3 channels\n",
    "\n",
    "    # Use EfficientNetB0 without pre-trained weights\n",
    "    base_model = applications.EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights=None,  # No pre-trained weights\n",
    "        input_tensor=x,  # Use the modified input tensor\n",
    "        pooling=\"avg\"  # Global average pooling\n",
    "    )\n",
    "\n",
    "    # Freeze the pre-trained layers (although there are none since we're training from scratch)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Add custom layers on top of EfficientNetB0\n",
    "    x = base_model.output\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # TABULAR INPUT BRANCH\n",
    "    tabular_input = layers.Input(shape=(tabular_input_dim,), name=\"tabular_input\")\n",
    "    tabular_x = layers.Dense(64, activation=\"relu\")(tabular_input)\n",
    "    tabular_x = layers.Dropout(0.5)(tabular_x)\n",
    "\n",
    "    # Concatenate image and tabular branches\n",
    "    combined = layers.concatenate([x, tabular_x])\n",
    "\n",
    "    # Output layer\n",
    "    output = layers.Dense(1, activation=\"sigmoid\")(combined)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs=[image_input, tabular_input], outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c3ac1-c3f2-4af9-aba0-2292c7cfa548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_image(path):\n",
    "    # Decode the tensor path into a string\n",
    "    if isinstance(path, tf.Tensor):\n",
    "        path = path.numpy().decode(\"utf-8\")  # Convert from Tensor to string\n",
    "    \n",
    "    dicom_data = pydicom.dcmread(path)\n",
    "    image_array = dicom_data.pixel_array.astype(np.float32)\n",
    "    image_array = resize(image_array, (224, 224), mode='constant', preserve_range=True)\n",
    "    image_array = np.expand_dims(image_array, axis=-1)  # Add channel dim\n",
    "    image_array /= 255.0  # normalize\n",
    "    return image_array\n",
    "\n",
    "def preprocess(image_path, tabular_row, label):\n",
    "    image = tf.py_function(func=load_dicom_image, inp=[image_path], Tout=tf.float32)\n",
    "    image.set_shape([224, 224, 1])  # Set static shape\n",
    "    return (image, tabular_row), label\n",
    "\n",
    "\n",
    "def create_dataset(image_paths, tabular_data, labels, batch_size=32, shuffle=True):\n",
    "    image_paths = tf.constant(image_paths)\n",
    "    tabular_data = tf.convert_to_tensor(tabular_data, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, tabular_data, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
    "\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_img_train, X_img_val, X_tab_train, X_tab_val, y_train, y_val = train_test_split(\n",
    "    image_paths, tabular_data, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_ds = create_dataset(X_img_train, X_tab_train, y_train, batch_size=32)\n",
    "val_ds = create_dataset(X_img_val, X_tab_val, y_val, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Build the model (make sure you define create_multimodal_model somewhere)\n",
    "model = create_multimodal_model(\n",
    "    image_shape=(224, 224, 1),  # CHANGED from 3 to 1 (grayscale)\n",
    "    tabular_input_dim=X_tab_train.shape[1]\n",
    ")\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Train\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=2, factor=0.5),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=6,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4022926d-4b41-43a8-9b53-70ee43fe0f81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7666afd4-3865-4703-ae1c-dab7e4c6bcbf",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce27372-fc5f-4764-92c5-3e4d28a5a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pydicom\n",
    "from skimage.transform import resize\n",
    "\n",
    "test_df = pd.read_csv(\"/kaggle/input/rsna-breast-cancer-detection/test.csv\")\n",
    "\n",
    "test_df[\"image_path\"] = test_df.apply(\n",
    "    lambda row: f\"/kaggle/input/rsna-breast-cancer-detection/test_images/{row['patient_id']}/{row['image_id']}.dcm\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "test_df = pd.get_dummies(test_df, columns=[\"view\", \"laterality\"], drop_first=False)\n",
    "\n",
    "tabular_features = [\"age\", \"implant\"] + [col for col in test_df.columns if col.startswith(\"view_\") or col.startswith(\"laterality_\")]\n",
    "X_tab_test = test_df[tabular_features].astype(np.float32).values\n",
    "\n",
    "print(test_df)  # Should output (N, 13), where N is the number of samples.\n",
    "\n",
    "X_img_test_paths = test_df[\"image_path\"].values\n",
    "prediction_ids = test_df[\"prediction_id\"].values\n",
    "\n",
    "NUM_TABULAR_FEATURES = X_tab_test.shape[1]\n",
    "\n",
    "def load_dicom_image(path):\n",
    "    if isinstance(path, tf.Tensor):\n",
    "        path = path.numpy().decode(\"utf-8\")\n",
    "\n",
    "    dicom = pydicom.dcmread(path)\n",
    "    img = dicom.pixel_array.astype(np.float32)\n",
    "    img = resize(img, (224, 224), mode='constant', preserve_range=True)\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    img /= 255.0\n",
    "    return img\n",
    "\n",
    "def preprocess_test(image_path, tabular_row):\n",
    "    image = tf.py_function(load_dicom_image, [image_path], tf.float32)\n",
    "    image.set_shape([224, 224, 1])\n",
    "    tabular_row.set_shape([NUM_TABULAR_FEATURES])\n",
    "    return (image, tabular_row)\n",
    "\n",
    "def create_test_dataset(image_paths, tabular_data, batch_size=32):\n",
    "    image_paths = tf.constant(image_paths)\n",
    "    tabular_data = tf.convert_to_tensor(tabular_data, dtype=tf.float32)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((image_paths, tabular_data))\n",
    "    ds = ds.map(preprocess_test, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "test_ds = create_test_dataset(X_img_test_paths, X_tab_test)\n",
    "\n",
    "# Debug one batch\n",
    "for images, tabular in test_ds.take(1):\n",
    "    print(\"Batch shapes:\")\n",
    "    print(\"Image batch:\", images.shape)        # (batch_size, 224, 224, 1)\n",
    "    print(\"Tabular batch:\", tabular.shape)      # (batch_size, NUM_TABULAR_FEATURES)\n",
    "\n",
    "model = tf.keras.models.load_model(\"best_model.keras\", compile=False)\n",
    "\n",
    "\n",
    "test_ds_for_pred = test_ds.map(lambda img, tab: (img, tab))\n",
    "preds = model.predict(test_ds_for_pred, verbose=1).squeeze()\n",
    "\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    \"prediction_id\": prediction_ids,\n",
    "    \"cancer\": preds\n",
    "})\n",
    "submission_df = submission_df.groupby(\"prediction_id\", as_index=False).mean()\n",
    "\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv is saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
